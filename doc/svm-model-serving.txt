Script to load the SVM model to Kafka Topic
-------------------------------------------

bin/zookeeper-server-start.sh config/zookeeper.properties &

0. (If not exists) create a multinode kafka cluster

cp config/server.properties config/server-1.properties
cp config/server.properties config/server-2.properties


config/server.properties:
    broker.id=0
    listeners=PLAINTEXT://:9092
    log.dir=/tmp/kafka-logs

config/server-1.properties:
    broker.id=1
    listeners=PLAINTEXT://:9093
    log.dir=/tmp/kafka-logs-1

config/server-2.properties:
    broker.id=2
    listeners=PLAINTEXT://:9094
    log.dir=/tmp/kafka-logs-2


bin/kafka-server-start.sh config/server.properties &    
bin/kafka-server-start.sh config/server-1.properties &
bin/kafka-server-start.sh config/server-2.properties &

1. (If not exists) create the kafka topic
=========================================

create topic ‘svm’
bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 3 --topic svm

check with a console consumer:
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092,localhost:9093,localhost:9094 --topic svm --from-beginning

2. Run Flink SVM
================

bin/flink run -c de.tub.it4bi.SVMImpl /Users/zis/git/flink-ms/flink-svm/target/flink-svm-1.0-SNAPSHOT.jar \
--training /Users/zis/Documents/IT4BI/semester-IV/data/url_svmlight_small \
--output /tmp/url_svmlight_out

3. Start the Flink Streaming application
========================================

bin/flink run -c de.tub.it4bi.modelserving.qs.SVMKafkaConsumer /Users/zis/git/flink-ms/svm-ms/target/svm-ms-1.0-SNAPSHOT.jar \
--topic svm \
--checkpointDataUri 'file:///tmp/checkpoint' \
--bootstrap.servers localhost:9092,localhost:9093,localhost:9094 \
--zookeeper.connect localhost:2181 \
--group.id svm-consumer-group \
--stateBackend rocksdb

4. Load the data
================

bin/flink run -c de.tub.it4bi.modelserving.qs.SVMKafkaProducer /Users/zis/git/flink-ms/svm-ms/target/svm-ms-1.0-SNAPSHOT.jar \
--input /tmp/url_svmlight_out \
--topic svm \
--bootstrap.servers localhost:9092,localhost:9093,localhost:9094

5. Cancel the job with a save point
===================================

bin/flink cancel -s [:targetDirectory] :jobId

bin/flink cancel -s /Users/zis/flink-state/savepoints/svm :jobId

6. Restart from savepoint
=========================

bin/flink run -s :savepointPath [:runArgs]

bin/flink run -s /Users/zis/flink-state/savepoints/svm/savepoint-id \
-c de.tub.it4bi.modelserving.qs.SVMKafkaConsumer /Users/zis/git/flink-ms/svm-ms/target/svm-ms-1.0-SNAPSHOT.jar \
--topic svm \
--checkpointDataUri 'file:///tmp/checkpoint' \
--bootstrap.servers localhost:9092,localhost:9093,localhost:9094 \
--zookeeper.connect localhost:2181 \
--group.id svm-consumer-group \
--stateBackend rocksdb

7. Query client
===============

java -cp flink-queryable-client/target/flink-queryable-client-1.0-SNAPSHOT-allinone.jar de.tub.it4bi.modelserving.qs.SVMPredictRandom \
--jobId  val \
--jobManagerHost val \
--jobManagerPort val \
--outputDecisionFunction val \
--thresholdValue val \
--numQueries val \
--maxNoOfFeatures val \
--minPercentageOfFeatures val \
--queryTimeout val \
--outputFile val

eg:

java -cp flink-queryable-client/target/flink-queryable-client-1.0-SNAPSHOT-allinone.jar de.tub.it4bi.modelserving.qs.SVMPredictRandom \
--jobId d49791b4a6c77e36380252c853334fc3 \
--numQueries 10000  \
--maxNoOfFeatures 323195  \
--outputFile /tmp/results.csv

8. To see the status
====================

kafka topic:
bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic als
bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list localhost:9092,localhost:9093,localhost:9094 -topic als

consumer group:
bin/kafka-consumer-groups.sh --describe --zookeeper localhost:2181  --describe  --group als-consumer-group
bin/kafka-consumer-groups.sh --list --zookeeper localhost:2181


9. To delete 
============

topic:
bin/kafka-run-class.sh kafka.admin.TopicCommand --zookeeper localhost:2181 --delete --topic als 
bin/kafka-topics.sh --delete  --zookeeper localhost:2181  --topic als

consumer group:
bin/kafka-consumer-groups.sh --zookeeper localhost:2181 --delete --group als-consumer-group

to delete savepoints:
bin/flink savepoint -d :savepointPath
bin/flink savepoint -d /Users/zis/flink-state/savepoints/svm


10. To shutdown kafka cluster
============================

bin/kafka-server-stop.sh
bin/zookeeper-server-stop.sh

# end of document

